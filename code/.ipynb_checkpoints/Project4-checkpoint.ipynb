{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/mosquito.jpg\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#37535e\">Healthy Chicago: West Nile Virus Prediction</span>\n",
    "\n",
    "### <span style=\"color:#3b748a\">Authors: Scott Wright, Alfred Lopez, Gwyneth Butera</span>\n",
    "    \n",
    "<span style=\"color:#3b748a\">Given weather, location, testing, and spraying data, this competition asks you to predict when and where different species of mosquitos will test positive for West Nile virus.</span>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/c/predict-west-nile-virus\">https://www.kaggle.com/c/predict-west-nile-virus</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#3b748a'>Table of contents</span>\n",
    "* <a href=\"#step1\"><span style='color:#4095b5'>Define the problem</span></a>\n",
    "* <a href=\"#step2\"><span style='color:#4095b5'>Obtain the data</span></a>\n",
    "* <a href=\"#step3\"><span style='color:#4095b5'>Explore the data</span></a>\n",
    "* <a href=\"#step4\"><span style='color:#4095b5'>Model the data</span></a>\n",
    "* <a href=\"#step5\"><span style='color:#4095b5'>Evaluate the model</span></a>\n",
    "* <a href=\"#step6\"><span style='color:#4095b5'>Answer the problem</span></a>\n",
    "* <a href=\"#step7\"><span style='color:#4095b5'>More modeling</span></a>\n",
    "* <a href=\"#step8\"><span style='color:#4095b5'>Future work</span></a>\n",
    "* <a href=\"#step9\"><span style='color:#4095b5'>For reference</span></a>\n",
    "\n",
    "## <span style='color:#3b748a'>Links</span>\n",
    "* <a href=\"../slides.pptx\"><span style='color:#4095b5'>Slide presentation</span></a>\n",
    "* <a href=\"https://github.com/gbkgwyneth/GA-DSI-project-04\"><span style='color:#4095b5'>On GitHub</span></a>\n",
    "* <a href=\"https://drive.google.com/open?id=1q-Tp-zzgZEtVuaDiUyzpCS9frsOv1DTB&usp=sharing\"><span style='color:#4095b5'>Spray map</span></a>\n",
    "* <a href=\"https://drive.google.com/open?id=1YyD5x8lXDe_t8fzrf6DpMOYlsMF8wGzl&usp=sharing\"><span style='color:#4095b5'>Spray 2011-09-07 map</span></a>\n",
    "* <a href=\"https://git.generalassemb.ly/gwynethbutera/ATL-gas-the-vectors\"><span style='color:#4095b5'>Traps map</span></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gwyneth/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Let's get the administrative stuff done first\n",
    "# import all the libraries and set up the plotting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, silhouette_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV \n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "colors_palette = sns.color_palette(\"GnBu_d\")\n",
    "sns.set_palette(colors_palette)\n",
    "\n",
    "# GnBu_d\n",
    "colors = ['#37535e', '#3b748a', '#4095b5', '#52aec9', '#72bfc4', '#93d0bf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#3b748a'>Data checking functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which non-numeric columns are missing values and what the possible values are for each object column\n",
    "\n",
    "def check_cols(df):\n",
    "    cols = df.select_dtypes([np.object]).columns\n",
    "    for col in cols:\n",
    "        print(\"{} is {} and values are {}.\".format(col,df[col].dtype,df[col].unique()))\n",
    "        n_nan = df[col].isnull().sum()\n",
    "        if n_nan > 0:\n",
    "            print(\"{} has {} NaNs.\".format(col,n_nan))\n",
    "            \n",
    "    cols = df.select_dtypes([np.int64,np.float64,np.uint64]).columns\n",
    "    for col in cols:\n",
    "        print(\"{} is {} and values are {} to {}.\".format(col,df[col].dtype,df[col].min(),df[col].max()))\n",
    "        n_nan = df[col].isnull().sum()\n",
    "        if n_nan > 0:\n",
    "            print(\"{} has {} NaNs.\".format(col,n_nan))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which numeric columns are missing values\n",
    "\n",
    "def check_data(df):\n",
    "    s = df.shape\n",
    "    print(\"Rows: {} Cols: {}\".format(s[0],s[1]))\n",
    "\n",
    "    # Check for null values\n",
    "    null_data = df.isnull().sum()\n",
    "    null_data_count = sum(df.isnull().sum())\n",
    "    if  null_data_count > 0:\n",
    "        print(\"There are {} null data.\".format(null_data_count))\n",
    "        print(\"Columns with NaN: {}\".format(list(null_data[null_data > 0].index)))\n",
    "\n",
    "    duplicates = df[df.duplicated()].shape[0]\n",
    "    print(\"There are {} duplicate rows in the test data.\".format(duplicates))\n",
    "\n",
    "    check_cols(df)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_examine_df(file):\n",
    "    df = pd.read_csv(file)\n",
    "    check_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    " <a name=\"step1\"></a>\n",
    " ## <span style=\"color:#37535e\">I. Define the problem</span>\n",
    " \n",
    "<span style='color:#3b748a'>Predict when and where different species of mosquitos will test positive for West Nile virus. A more accurate method of predicting outbreaks of West Nile virus in mosquitos will help the City of Chicago and CPHD more efficiently and effectively allocate resources towards preventing transmission of this potentially deadly virus.</span>\n",
    "\n",
    "<span style='color:#3b748a'>For each record in the test set, you should predict a real-valued probability that WNV is present.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step2\"></a>\n",
    " ## <span style=\"color:#37535e\">II. Obtain the data.</span>\n",
    " \n",
    "<ul>\n",
    "    <li><span style='color:#3b748a'>Training data: <span style=\"font-family:monospace\">train.csv</span></span></li>\n",
    "    <li><span style='color:#3b748a'>Test data: <span style=\"font-family:monospace\">test.csv</span></span></li>\n",
    "    <li><span style='color:#3b748a'>Spray data: <span style=\"font-family:monospace\">spray.csv</span></span></li>\n",
    "    <li><span style='color:#3b748a'>Weather data: <span style=\"font-family:monospace\">weather.csv</span></span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Training data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Rows: 10506</span></li\n",
    "        >\n",
    "    <li><span style='color:#4095b5'>Cols: 12</span></li>\n",
    "    <li><span style='color:#4095b5'>There is NO null data.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_check_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_check_data:\n",
    "    df_train = read_examine_df(\"../data/train.csv\")\n",
    "else:\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cleaning the training data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Latitude and longitude have reasonable ranges.</span></li>\n",
    "    <li><span style='color:#4095b5'>Drop all other address data for now.</span></li>\n",
    "    <li><span style='color:#4095b5'>Replace <span style=\"font-family:monospace\">Date</span>  with a <span style=\"font-family:monospace\">datetime</span> object.</span></li>\n",
    "    <li><span style='color:#4095b5'>Create <span style=\"font-family:monospace\">Week</span> and <span style=\"font-family:monospace\">Year</span> features.</span></li>\n",
    "    <li><span style='color:#4095b5'>(Removed) Merge rows with same trap/date/species; sum <span style=\"font-family:monospace\">NumMosquitos</span> and set <span style=\"font-family:monospace\">WnvPresent</span> to 0 or 1 acordingly. This may cause us to lose some information. Scott and Al convinced Gwyneth that this is a bad idea overall. There might be some value in the aggregatingg if done at the right times.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, drop all the address columns since lat/lon should be enough\n",
    "df_train.drop(['Address','Block','Street','AddressNumberAndStreet','AddressAccuracy'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Date into datetime\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "\n",
    "# Add week and Year columns\n",
    "df_train['Week'] = (df_train['Date'].dt.strftime('%W')).astype(int)\n",
    "df_train['Year'] = (df_train['Date'].dt.strftime('%Y')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>(Removed) Aggregate split rows</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model works better without aggregating, but there maybe a use for it\n",
    "\n",
    "# Merge duplicate rows by summing NumMosquiots and WMvPresent\n",
    "# df_train = df_train.groupby(['Date','Week','Year','Species','Trap','Latitude', 'Longitude'], as_index=False).sum().reindex()\n",
    "# Change WnvPresent to be  0/1\n",
    "# df_train['WnvPresent'] = (df_train['WnvPresent'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Plot mosquito totals by week and species</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the TOTAL mosquitos in a given week summed over all years.\n",
    "df_temp = df_train.groupby(['Week','Species'], as_index=False).sum().reindex()\n",
    "\n",
    "fg = sns.lmplot(data=df_temp, x = 'Week', y='NumMosquitos', hue='Species', fit_reg=False);\n",
    "fg.fig.set_figheight(6)\n",
    "fg.fig.set_figwidth(15)\n",
    "fg.fig.suptitle(\"Total for each species per week over all years\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speies with West Nile Virus\n",
    "species_wnv = set((df_train[df_train['WnvPresent'] > 0])['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Create \"target\" variables</span>\n",
    "\n",
    "<span style='color:#4095b5'>There are TWO targets in this problem:</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>First, we have to predict HOW MANY mosquitoes of each species will be in a trap on a given date.</span></li>\n",
    "    <li><span style='color:#4095b5'>Then we have to predict the probablity that there will be West Nile virus present based on those counts.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our targets then drop those columns\n",
    "\n",
    "y_count_label = 'NumMosquitos'\n",
    "y_count = df_train[y_count_label]\n",
    "\n",
    "y_wnv_label = 'WnvPresent'\n",
    "y_wnv = df_train[y_wnv_label]\n",
    "\n",
    "df_train.drop(columns=[y_wnv_label,y_count_label], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Kaggle data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Rows: 116293</span></li>\n",
    "    <li><span style='color:#4095b5'>Cols: 11</span></li>\n",
    "    <li><span style='color:#4095b5'>There is NO null data.</span></li>\n",
    "</ul>\n",
    "\n",
    "<span style='color:#4095b5'>The instructions say that we are predicting all combinations of possible traps/dates/species, but we will only be scored on the records that match with actual tests/samples.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_check_data:\n",
    "    df_kaggle = read_examine_df(\"../data/test.csv\")\n",
    "else:\n",
    "    df_kaggle = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cleaning the Kaggle data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Latitude and longitude have reasonable ranges.</span></li>\n",
    "    <li><span style='color:#4095b5'>Drop all other address data for now.</span></li>\n",
    "    <li><span style='color:#4095b5'>Replace <span style=\"font-family:monospace\">Date</span>  with a <span style=\"font-family:monospace\">datetime</span> object.</span></li>\n",
    "    <li><span style='color:#4095b5'>Create <span style=\"font-family:monospace\">Week</span> and <span style=\"font-family:monospace\">Year</span> features.</span></li>\n",
    "    <li><span style='color:#4095b5'>There are duplicate rows. Can we assume anything about these? We merged rows like this in training, but we need to make predictions here.</span></li>\n",
    "</ul>    \n",
    "\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Does not have <span style=\"font-family:monospace\">NumMosquitos</span> nor <span style=\"font-family:monospace\">WnvPresent</span>. These are what we need to predict.</span></li>\n",
    "    <li><span style='color:#4095b5'>Does have <span style=\"font-family:monospace\">Id</span> column - later on, make this the index?</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, drop all the address columns since lat/lon should be enough\n",
    "df_kaggle.drop(['Address','Block','Street','AddressNumberAndStreet','AddressAccuracy'], axis=1,inplace=True)\n",
    "\n",
    "# Make Date into datetime\n",
    "df_kaggle['Date'] = pd.to_datetime(df_kaggle['Date'])\n",
    "\n",
    "# Add week and 'Year' feature\n",
    "df_kaggle['Week'] = (df_kaggle['Date'].dt.strftime('%W')).astype(int)\n",
    "df_kaggle['Year'] = (df_kaggle['Date'].dt.strftime('%Y')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1533 duplicate rows in the test data.\n"
     ]
    }
   ],
   "source": [
    "# If there is a duplicate row, maybe that means we know there are more than 50 in trap?\n",
    "kaggle_cols = list(df_kaggle.columns)\n",
    "kaggle_cols.remove('Id')\n",
    "duplicates = df_kaggle[df_kaggle.duplicated(kaggle_cols)].shape[0]\n",
    "print(\"There are {} duplicate rows in the test data.\".format(duplicates))\n",
    "\n",
    "# There are 1533 duplicate rows in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>23</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>23</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX PIPIENS</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>23</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX SALINARIUS</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>23</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX TERRITANS</td>\n",
       "      <td>T002</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>23</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       Date                 Species  Trap  Latitude  Longitude  Week  \\\n",
       "0   1 2008-06-11  CULEX PIPIENS/RESTUANS  T002  41.95469 -87.800991    23   \n",
       "1   2 2008-06-11          CULEX RESTUANS  T002  41.95469 -87.800991    23   \n",
       "2   3 2008-06-11           CULEX PIPIENS  T002  41.95469 -87.800991    23   \n",
       "3   4 2008-06-11        CULEX SALINARIUS  T002  41.95469 -87.800991    23   \n",
       "4   5 2008-06-11         CULEX TERRITANS  T002  41.95469 -87.800991    23   \n",
       "\n",
       "   Year  \n",
       "0  2008  \n",
       "1  2008  \n",
       "2  2008  \n",
       "3  2008  \n",
       "4  2008  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cleaning the trap data</span>\n",
    "\n",
    "<span style='color:#4095b5'>While working to feature engineer the spraying data, we noticed that there are two traps that each have two different locations listed in the observation data. We rename these traps and also rename them in the Kaggle test data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138 traps in the test data.\n",
      "There are 2 bad traps in the training data. Now cleaning.\n",
      "There are 151 traps in the Kaggle data.\n"
     ]
    }
   ],
   "source": [
    "# Break apart duplicate traps !\n",
    "df_traps_train = df_train[['Trap', 'Latitude','Longitude']].copy()\n",
    "df_traps_train.drop_duplicates(inplace=True)\n",
    "df_traps_train.reset_index(inplace=True)\n",
    "print(\"There are {} traps in the test data.\".format(df_traps_train.shape[0]))\n",
    "\n",
    "# Here are the traps with duplicates\n",
    "df_trap_duplicate = df_traps_train.loc[df_traps_train.duplicated('Trap')][['Trap','Latitude','Longitude']].copy()\n",
    "if df_trap_duplicate.shape[0] > 0:\n",
    "    print(\"There are {} bad traps in the training data. Now cleaning.\".format(df_trap_duplicate.shape[0]))\n",
    "    \n",
    "# For each one, update the Train and Kaggle data too...\n",
    "for i in df_trap_duplicate.index:\n",
    "    trap = df_trap_duplicate.loc[i, \"Trap\"]\n",
    "    lat = df_trap_duplicate.loc[i, \"Latitude\"]\n",
    "    long = df_trap_duplicate.loc[i, \"Longitude\"]\n",
    "    new_trap = trap + \"GAS\"\n",
    "    df_train.loc[(df_train['Trap'] == trap) \n",
    "                 & (df_train['Latitude'] == lat) \n",
    "                 & (df_train['Longitude'] == long),'Trap'] = new_trap\n",
    "    df_kaggle.loc[(df_kaggle['Trap'] == trap) \n",
    "                 & (df_kaggle['Latitude'] == lat) \n",
    "                 & (df_kaggle['Longitude'] == long),'Trap'] = new_trap\n",
    "\n",
    "# Repeat with Kaggle data\n",
    "df_traps_kaggle = df_kaggle[['Trap', 'Latitude','Longitude']].copy()\n",
    "df_traps_kaggle.drop_duplicates(inplace=True)\n",
    "df_traps_kaggle.reset_index(inplace=True)\n",
    "print(\"There are {} traps in the Kaggle data.\".format(df_traps_kaggle.shape[0]))\n",
    "\n",
    "# Any more with duplicates\n",
    "df_trap_duplicate = df_traps_kaggle.loc[df_traps_kaggle.duplicated('Trap')][['Trap','Latitude','Longitude']].copy()\n",
    "if df_trap_duplicate.shape[0] > 0:\n",
    "    print(\"There are {} bad traps in the Kaggle test data. Error: More cleaning needed.\".format(df_trap_duplicate.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Spray data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Rows: 14835</span></li\n",
    "        >\n",
    "    <li><span style='color:#4095b5'>Cols: 4</span></li>\n",
    "    <li><span style='color:#4095b5'>There are 584 null data.</span></li>\n",
    "    <li><span style='color:#4095b5'>There are 541 duplicate rows.</span></li>\n",
    "    <li><span style='color:#4095b5'>Columns with NaN: <span style=\"font-family:monospace\">Time</span></span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:56:58 PM</td>\n",
       "      <td>42.391623</td>\n",
       "      <td>-88.089163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:08 PM</td>\n",
       "      <td>42.391348</td>\n",
       "      <td>-88.089163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:18 PM</td>\n",
       "      <td>42.391022</td>\n",
       "      <td>-88.089157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:28 PM</td>\n",
       "      <td>42.390637</td>\n",
       "      <td>-88.089158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:38 PM</td>\n",
       "      <td>42.390410</td>\n",
       "      <td>-88.088858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Time   Latitude  Longitude\n",
       "0  2011-08-29  6:56:58 PM  42.391623 -88.089163\n",
       "1  2011-08-29  6:57:08 PM  42.391348 -88.089163\n",
       "2  2011-08-29  6:57:18 PM  42.391022 -88.089157\n",
       "3  2011-08-29  6:57:28 PM  42.390637 -88.089158\n",
       "4  2011-08-29  6:57:38 PM  42.390410 -88.088858"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if do_check_data:\n",
    "    df_spray = read_examine_df(\"../data/spray.csv\")\n",
    "else: \n",
    "    df_spray = pd.read_csv(\"../data/spray.csv\")\n",
    "df_spray.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cleaning the spray data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Latitude and longitude have reasonable ranges.</span></li>\n",
    "    <li><span style='color:#4095b5'>Missing <span style=\"font-family:monospace\">Time</span> data on date 2011-09-07</span></li>\n",
    "    <li><span style='color:#4095b5'>Drop (~450) duplicate rows: <br />2011-09-07\t7:44:32 PM\t41.98646\t-87.794225</span></li>\n",
    "    <li><span style='color:#4095b5'>Add <span style=\"font-family:monospace\">DateTime</span> column and change <span style=\"font-family:monospace\">Date</span> to a <span style=\"font-family:monospace\">datetime</span> object.</span></li>\n",
    "</ul>\n",
    "\n",
    "#### <span style='color:#4095b5'>Spraying maps</span>\n",
    "<ul>\n",
    "    <li><a href=\"https://drive.google.com/open?id=1q-Tp-zzgZEtVuaDiUyzpCS9frsOv1DTB&usp=sharing\"><span style='color:#4095b5'>All the spraying data, execpt for the date with bad data</span></a></li>\n",
    "    <li><a href=\"https://drive.google.com/open?id=1YyD5x8lXDe_t8fzrf6DpMOYlsMF8wGzl&usp=sharing\"><span style='color:#4095b5'>Spray 2011-0907 map</span></a></li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style='color:#4095b5'>Map of all spraying except for 2011-09-07</span></center>\n",
    "<img src=\"../images/spray-map.jpg\" alt=\"Full spray map\" width=700/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style='color:#4095b5'>Map of all spraying on 2011-0907</span></center>\n",
    "<img src=\"../images/spray-2011-09-07.jpg\" alt=\"Spray map for 2011-09-07\" width=700/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Missing spray time data for 2011-09-07</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Many <span style=\"font-family:monospace\">Time</span> values are missing but can likely be imputed.</span></li>\n",
    "    <li><span style='color:#4095b5'>Spraying generally happens every 10 seconds. </span></li>\n",
    "    <li><span style='color:#4095b5'>As the previous rows were the duplicate data, I'm going to guess that we should connect with 7:44:32.</span>\n",
    "    <li><span style='color:#4095b5'>Based the spray time on the endpoints.</span>\n",
    "    <li><span style='color:#4095b5'>Probably good enough to have the time within a small window of time.</span>\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This spray time imputation is overkill, but it was fun to tackle.\n",
    "\n",
    "# Get time of duplicate row\n",
    "# Make it the start for the next set of columns\n",
    "# fill the NaNs, *subtracting* ten seconds based on the map of the missing data\n",
    "\n",
    "# Get time of duplicate row\n",
    "series = df_spray[df_spray.duplicated() == True].index\n",
    "idx = series[-1]\n",
    "\n",
    "# Check the next row starts the Nans\n",
    "# print(\"If it is not a NaN, we have a problem... {}\".format(df_spray.loc[idx+1]['Time']))\n",
    "\n",
    "# Assume the NaNs are in a row\n",
    "null_data_count = sum(df_spray.isnull().sum())\n",
    "# print(\"If it is not a NaN, we have a problem... {}\".format(df_spray.iloc[idx+null_data_count]['Time']))\n",
    "# print(\"If it IS a NaN, we have a problem... {}\".format(df_spray.iloc[idx+null_data_count+1]['Time']))\n",
    "\n",
    "# Make it the start for the next row\n",
    "start_time = pd.to_datetime(df_spray.iloc[idx]['Time'])\n",
    "times = [(start_time + timedelta(seconds=-10*i)).time().strftime('%H:%M:%S')\n",
    "         for i in range(null_data_count)]\n",
    "\n",
    "# Replace the missing times\n",
    "df_spray.loc[df_spray['Time'].isnull(), 'Time'] = times\n",
    "\n",
    "# Check that there are no longer any nulls\n",
    "null_data_count = sum(df_spray.isnull().sum())\n",
    "if  null_data_count > 0:\n",
    "    print(\"There are {} null data.\".format(null_data_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_spray.drop_duplicates(keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Other spray cleaning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:56:58 PM</td>\n",
       "      <td>42.391623</td>\n",
       "      <td>-88.089163</td>\n",
       "      <td>2011-08-29 18:56:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:08 PM</td>\n",
       "      <td>42.391348</td>\n",
       "      <td>-88.089163</td>\n",
       "      <td>2011-08-29 18:57:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:18 PM</td>\n",
       "      <td>42.391022</td>\n",
       "      <td>-88.089157</td>\n",
       "      <td>2011-08-29 18:57:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:28 PM</td>\n",
       "      <td>42.390637</td>\n",
       "      <td>-88.089158</td>\n",
       "      <td>2011-08-29 18:57:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>6:57:38 PM</td>\n",
       "      <td>42.390410</td>\n",
       "      <td>-88.088858</td>\n",
       "      <td>2011-08-29 18:57:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Time   Latitude  Longitude            DateTime\n",
       "0 2011-08-29  6:56:58 PM  42.391623 -88.089163 2011-08-29 18:56:58\n",
       "1 2011-08-29  6:57:08 PM  42.391348 -88.089163 2011-08-29 18:57:08\n",
       "2 2011-08-29  6:57:18 PM  42.391022 -88.089157 2011-08-29 18:57:18\n",
       "3 2011-08-29  6:57:28 PM  42.390637 -88.089158 2011-08-29 18:57:28\n",
       "4 2011-08-29  6:57:38 PM  42.390410 -88.088858 2011-08-29 18:57:38"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the Date/Time into a datetime object\n",
    "df_spray['DateTime'] = pd.to_datetime(df_spray['Date'] + \" \" + df_spray['Time'])\n",
    "\n",
    "# Make Date into datetime\n",
    "df_spray['Date'] = pd.to_datetime(df_spray['Date'])\n",
    "\n",
    "# df_spray.drop(['Date','Time'], axis=1, inplace=True)\n",
    "df_spray.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Weather data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Rows: 2944</span></li>\n",
    "    <li><span style='color:#4095b5'>Cols: 22</span></li>\n",
    "    <li><span style='color:#4095b5'>There is NO null data.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_check_data:\n",
    "    df_weather = read_examine_df(\"../data/weather.csv\")\n",
    "else:\n",
    "    df_weather = pd.read_csv(\"../data/weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cleaning the weather data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>For now, keep only a subset of the columns: <span style=\"font-family:monospace\">Date</span>, <span style=\"font-family:monospace\">WetBulb</span>, <span style=\"font-family:monospace\">Sunrise</span>, <span style=\"font-family:monospace\">Sunset</span>, <span style=\"font-family:monospace\">PrecipTotal</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>For the places where <span style=\"font-family:monospace\">WetBulb</span> is 'M', use the value from the other station.</span></li>\n",
    "    <li><span style='color:#4095b5'>Get rid of Station 2, then drop <span style=\"font-family:monospace\">Station</span> column since all are Station 1.</span></li>\n",
    "    <li><span style='color:#4095b5'>Replace <span style=\"font-family:monospace\">Trace</span> with 0.1.</span></li>\n",
    "    <li><span style='color:#4095b5'>Change type of <span style=\"font-family:monospace\">WetBulb</span> and <span style=\"font-family:monospace\">PrecipTotal</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>Change <span style=\"font-family:monospace\">Sunrise</span> and <span style=\"font-family:monospace\">Sunset</span> to a <span style=\"font-family:monospace\">datetime</span> object - clean the 1860(?!?) sunset.</span></li>\n",
    "    <li><span style='color:#4095b5'>Change <span style=\"font-family:monospace\">Date</span> to <span style=\"font-family:monospace\">datetime</span> and add <span style=\"font-family:monospace\">Week</span> and <span style=\"font-family:monospace\">Year</span>.</span></li>\n",
    "</ul>\n",
    "\n",
    "<span style=\"font-family:monospace\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>56</td>\n",
       "      <td>2007-05-01 04:48:00</td>\n",
       "      <td>2007-05-01 18:49:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2007-05-02</td>\n",
       "      <td>47</td>\n",
       "      <td>2007-05-02 04:47:00</td>\n",
       "      <td>2007-05-02 18:50:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>48</td>\n",
       "      <td>2007-05-03 04:46:00</td>\n",
       "      <td>2007-05-03 18:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2007-05-04</td>\n",
       "      <td>50</td>\n",
       "      <td>2007-05-04 04:44:00</td>\n",
       "      <td>2007-05-04 18:52:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2007-05-05</td>\n",
       "      <td>49</td>\n",
       "      <td>2007-05-05 04:43:00</td>\n",
       "      <td>2007-05-05 18:53:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date  WetBulb             Sunrise              Sunset  \\\n",
       "0      0 2007-05-01       56 2007-05-01 04:48:00 2007-05-01 18:49:00   \n",
       "1      2 2007-05-02       47 2007-05-02 04:47:00 2007-05-02 18:50:00   \n",
       "2      4 2007-05-03       48 2007-05-03 04:46:00 2007-05-03 18:51:00   \n",
       "3      6 2007-05-04       50 2007-05-04 04:44:00 2007-05-04 18:52:00   \n",
       "4      8 2007-05-05       49 2007-05-05 04:43:00 2007-05-05 18:53:00   \n",
       "\n",
       "   PrecipTotal  Week  Year  \n",
       "0          0.0    18  2007  \n",
       "1          0.0    18  2007  \n",
       "2          0.0    18  2007  \n",
       "3          0.1    18  2007  \n",
       "4          0.1    18  2007  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only these columns\n",
    "cols_keep = ['Station', 'Date', 'WetBulb', 'Sunrise', 'Sunset', 'PrecipTotal']\n",
    "df_weather = df_weather[cols_keep].copy()\n",
    "\n",
    "# Clean the data\n",
    "# Replace 'M' with other station's WetBulb\n",
    "# This should have error checking?\n",
    "missing = df_weather[df_weather['WetBulb'] == 'M'].index\n",
    "for i in missing:\n",
    "    df_weather.loc[i,'WetBulb'] = df_weather.loc[i+1,'WetBulb']\n",
    "if len(df_weather[df_weather['WetBulb'] == 'M'].index) > 0:\n",
    "    print(\"More Wetbulb cleaning to do!!!\")\n",
    "\n",
    "# Get rid of Station 2, then drop Station column since all rows are Station 1\n",
    "df_weather = df_weather[df_weather['Station'] == 1].copy()\n",
    "df_weather.reset_index(inplace=True)\n",
    "df_weather.drop(columns='Station', inplace=True)\n",
    "\n",
    "# Replace \"Trace\" with 0.1\n",
    "df_weather['PrecipTotal'].replace(to_replace='  T',value = '0.1', inplace=True)\n",
    "\n",
    "# Change type\n",
    "df_weather['WetBulb'] = df_weather['WetBulb'].astype(int)\n",
    "df_weather['PrecipTotal'] = df_weather['PrecipTotal'].astype(float)\n",
    "\n",
    "# Really? Rounding error?\n",
    "# Should do more generalized cleaning/checking for these\n",
    "df_weather['Sunset'].replace(to_replace='1860',value = '1900', inplace=True)\n",
    "df_weather['Sunset'].replace(to_replace='1760',value = '1900', inplace=True)\n",
    "df_weather['Sunset'].replace(to_replace='1660',value = '1900', inplace=True)\n",
    "\n",
    "# Change Sunrise and Sunset to a datetime object\n",
    "sunrise = df_weather['Date'] + \" \" + df_weather[\"Sunrise\"]\n",
    "df_weather['Sunrise'] = pd.to_datetime(sunrise, format=\"%Y-%m-%d %H%M\")\n",
    "sunset = df_weather['Date'] + \" \" + df_weather[\"Sunset\"]\n",
    "df_weather['Sunset'] = pd.to_datetime(sunset, format=\"%Y-%m-%d %H%M\")\n",
    "\n",
    "# Change Date to datetime and add Week and Year\n",
    "df_weather['Date'] = pd.to_datetime(df_weather['Date'])\n",
    "df_weather['Week'] = (df_weather['Date'].dt.strftime('%W')).astype(int)\n",
    "df_weather['Year'] = (df_weather['Date'].dt.strftime('%Y')).astype(int)\n",
    "\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#37535e'><b>Weekly data showing Number of Mosquitoes Collected in Traps vs Average Daily Rainfall</b></span>\n",
    "\n",
    "<span style='color:#3b748a'>Refer to the <a href=\"#avg_prec\"><span style='color:#3b748a'>\"Average precipitation calculations\" section</span></a> for the code to generate this chart.</span>\n",
    "\n",
    "<img src=\"../images/rainfall.jpg\" alt=\"rainfall\" width=6800/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#37535e'><b>Summary of the data</b></span><br />\n",
    "<span style='color:#3b748a'>For this project on mosquitos and the spread of West Nile Virus in Chicago, we were provided with three spreadsheets of data: the observations from mosquito traps around the city, weather data, and mosquito spraying data. We were also provided with a set of trap, date, and species tuples for which we were to predict the probability of finding West Nile virus.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style=\"color:#37535e\"><b>Initial data cleaning</b></span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'><b>Training data</b></span><br />\n",
    "<span style='color:#3b748a'>The training data has approximately 10K rows and 12 columns. There is no null data. The rows represent the trap observations, broken down by Trap, Date, and Species.  Seven of the twelve columns refer to the location of the trap. A quick check of the ranges of the latitude and longitude of the the traps as well as a quick map of the locations confirm the accuracy of the latitude and longitude, so we dropped all other information regarding the address. The final two columns relate to the mosquitos in the trap: how many of each species were counted and a Boolean for whether or not West Nile was observed in the count.\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>In addition, we transformed the Date data into a <span style=\"font-family:monospace\">datetime</span> object in order to more easily calculate difference in days between observations and other such metrics. We also added in a column for Week and Year in order to aggregate observations.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>In pursuing some feature engineering, we noticed that there were two traps (T009 and T035) that were placed in two different locations at different times. We \"split\" these traps and made the same change to the prediction data.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>It is interesting to note that if a trap had more than 50 mosquitos in it, the observation is split into two observations. We debated whether or not to aggregate the rows. On one had, aggregating would give a better value for predicting the number of mosquitos that might be found in a trap. On the other hand, we would lose information about the number of cases of West Nile found.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Prediction data</b></span><br />\n",
    "<span style='color:#3b748a'>The prediction data has approximately 116K rows (10x as many as the observations) and 11 columns. There is no null data. The rows represent the trap observations we need to predict, broken down by Id, Trap, Date, and Species; the Id is for Kaggle reporting purposes only.  Seven of the eleven columns refer to the location of the trap, and, as with the training data, we drop all these except for latitude and longitude.</span>\n",
    "<br /><br /> \n",
    "<span style='color:#3b748a'>As with the training data, we transform the Date data into a <span style=\"font-family:monospace\">datetime</span> object in order to more easily calculate difference in days between observations and other such metrics. We also add in a column for Week and Year.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>Also, like with the training data, there are duplicate rows (1533). Later on, as we model, we make some assumptions about what these represent.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'><b>Spraying data</b></span><br />\n",
    "<span style='color:#3b748a'>The spraying data has approximately 15K rows and 4 columns. The columns are Date, Time, Latitude, and Longitude. There are 450 duplicate rows and also around 450 rows that are missing Time entries. (Something went wrong in recording data.) We mapped all the spraying data, broken down by day, and all the locations appeared to be reasonable, except for the \"Oops\" moment on 2011-09-07.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>To fix the bad spraying data, we mapped the spraying for that day, located where the observations with missing times were, and imputed the times based on noting that spraying location/time is recorded about every ten seconds. We worked harder on this than was <strike>probably</strike> necessary since spraying all happens within a small time-window.\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'><b>Weather data</b></span><br />\n",
    "<span style='color:#3b748a'>The weather data has approximately 3K rows and 22 columns with no missing data. The readings are taken once a day at two different stations. These observations include precipitation totals, temperature measures, sunrise, sunset, wind and humidity measurements. </span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>For now, we only keep the columns Date, Sunrise, Sunset, WetBulb, and PrecipTotal. We also only keep the rows from the first weather station. The precipitation column has a 'T' for some entries; we changed this 'trace' into 0.1. For the 'M' readings in WetBulb, we used the data from the other station on the same day. In translating the Sunrise and Sunset times to a datetime object, we encountered that some of the times were given as 1860, etc, and needed to be corrected.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#37535e'><b>Preliminary Exploratory Data Analysis</b></span><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Observation data</b></span><br />\n",
    "<span style='color:#3b748a'>The dates of the observation data are approximately weekly from the end of May to the beginning of October for the years 2007, 2009, 2011, 2013. There are seven different species of mosquito in the observations, and an additional one in the set we are asked to predict. For the observations, the only Species that had West Nile Virus present were : CULEX PIPIENS', 'CULEX PIPIENS/RESTUANS', and 'CULEX RESTUANS', and there were a total of 135039 mosquitos observed. West Nile was observed 551 times.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Prediction data</b></span><br />\n",
    "<span style='color:#3b748a'>The dates of the prediction data are approximately weekly from the end of May to the beginning of October for the years 2008, 2010, 2012, 2014. There are eight Species of mosquitos that we need to predict for.</span>\n",
    "</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Spray data</b></span><br />\n",
    "<span style='color:#3b748a'>We have spraying data for ten different dates in 2011 and 2013. Spraying occurred in the evenings between 7pm and 9pm. We mapped the spray areas, and the spraying covered ten different neighborhoods.\n",
    "</span>\n",
    "<br /><br />\n",
    "    \n",
    "<span style='color:#3b748a'><b>Traps data</b></span><br />\n",
    "<span style='color:#3b748a'>Combining the trap data found in the observations and the prediction data, there are 151 traps (after splitting the two traps that reported two locations), spread throughout the city.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Weather data</b></span><br />\n",
    "<span style='color:#3b748a'>We did not have time to deeply explore the weather data. Through plotting, we visually noticed a correlation between precipitation and a spike in trap populations 3-4 weeks later.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step3\"></a>\n",
    "## <span style='color:#37535e'>Exploratory data analysis (EDA)</span>\n",
    " * <span style=\"color:#3b748a\">How do we model traps NOT in training data? (Cluster?)</span>\n",
    " * <span style=\"color:#3b748a\">We need to engineer features based on spray and weather to add to the observation data and the Kaggle test data.</span>\n",
    " * <span style='color:#3b748a'>How many \"categorical\" features remain?</span>\n",
    " * <span style=\"color:#3b748a\">Make dummies for all categorical data.</span>\n",
    " * <span style=\"color:#3b748a\">Which features should we drop?</span>\n",
    " * <span style=\"color:#3b748a\">Are there any interesting linear relationships?</span>\n",
    " \n",
    "### <span style='color:#3b748a'>New features</span>\n",
    " \n",
    "<ol>\n",
    "    <li><span style='color:#4095b5'>Let's add a column of \"Days since emptied\" to indicate how long it has been since the trap was emptied.</span>\n",
    "    <li><span style='color:#4095b5'>Let's add a column of \"Days since sprayed\" to indicate how long it has been since the area near the trap was sprayed.</span>\n",
    "        <li><span style='color:#4095b5'>Since there are traps in the Kaggle test set but not in the observations set, we need to make some inferences. We chose to start by clustering the traps.</span>\n",
    "</ol>\n",
    "\n",
    "### <span style='color:#3b748a'>Spray data</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>How long has it been since we have sprayed?</span></li>\n",
    "    <li><span style='color:#4095b5'>Add a column to train/kaggle data for \"Days since sprayed\"?</span></li>\n",
    "    <li><span style='color:#4095b5'>Are there any mosquitos in traps \"near\" where we spray those dates?</span></li>\n",
    "</ul>\n",
    "\n",
    "#### <span style='color:#4095b5'>Create a dataframe for traps.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 151 traps.\n"
     ]
    }
   ],
   "source": [
    "# What are all the traps?\n",
    "df_traps_train = df_train[['Trap', 'Latitude','Longitude']].copy()\n",
    "df_traps_train.drop_duplicates(inplace=True)\n",
    "\n",
    "df_traps_kaggle = df_kaggle[['Trap', 'Latitude','Longitude']].copy()\n",
    "df_traps_kaggle.drop_duplicates(inplace=True)\n",
    "\n",
    "# Merge the dataframes and set the index to be the traps\n",
    "df_traps = pd.concat([df_traps_train,df_traps_kaggle])\n",
    "df_traps.drop_duplicates(inplace=True)\n",
    "df_traps.set_index(['Trap'], inplace=True)\n",
    "\n",
    "print(\"There are {} traps.\".format(df_traps.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Determine dates that area near each trap was sprayed.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = .01\n",
    "\n",
    "# Create a set of spray dates for each trap based on lat/log with epsilon\n",
    "traps = list(set(df_traps.index))\n",
    "traps.sort()\n",
    "\n",
    "spray_dates = []\n",
    "for t in traps:\n",
    "    # This area near trap could be sprayed from this \"radius\"\n",
    "    # Needs much improvement\n",
    "    min_lat = df_traps.loc[t,'Latitude'] - epsilon\n",
    "    max_lat = df_traps.loc[t,'Latitude'] + epsilon\n",
    "    min_lon = df_traps.loc[t,'Longitude'] - epsilon\n",
    "    max_lon = df_traps.loc[t,'Longitude'] + epsilon\n",
    "\n",
    "    df_temp = df_spray[df_spray['Latitude'] < max_lat]\n",
    "    df_temp = df_temp[df_temp['Latitude'] > min_lat]\n",
    "    df_temp = df_temp[df_temp['Longitude'] < max_lon]\n",
    "    df_temp = df_temp[df_temp['Longitude'] > min_lon]\n",
    "\n",
    "    spray_dates.append(set(df_temp['Date']))\n",
    "\n",
    "df_traps['SprayDates'] = spray_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Add a column to training and Kaggle dataframes for \"SprayDates\".</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_since_sprayed = False\n",
    "if do_since_sprayed:    \n",
    "    df_train[\"SinceSprayed\"] = 999\n",
    "\n",
    "    for i in range(df_train.shape[0]):\n",
    "        trap = df_train.loc[i,\"Trap\"]\n",
    "        date = df_train.loc[i,\"Date\"]  \n",
    "        spray_dates = [d for d in df_traps.loc[trap,\"SprayDates\"] if d < date]\n",
    "        if spray_dates:\n",
    "            elapsed = (date - max(spray_dates)).days\n",
    "            df_train.loc[i,\"SinceSprayed\"] = elapsed\n",
    "\n",
    "    df_kaggle[\"SinceSprayed\"] = 999\n",
    "\n",
    "    for i in range(df_kaggle.shape[0]):\n",
    "        trap = df_kaggle.loc[i,\"Trap\"]\n",
    "        date = df_kaggle.loc[i,\"Date\"]  \n",
    "        spray_dates = [d for d in df_traps.loc[trap,\"SprayDates\"] if d < date]\n",
    "        if spray_dates:\n",
    "            elapsed = (date - max(spray_dates)).days\n",
    "            df_kaggle.loc[i,\"SinceSprayed\"] = elapsed\n",
    "            \n",
    "    print(\"Minimum days since trap in training set sprayed: {}.\".format(min(df_train['SinceSprayed'])))\n",
    "    print(\"Minimum days since trap in Kaggle set sprayed: {}.\".format(min(df_kaggle['SinceSprayed'])))\n",
    "\n",
    "    # I may just use a flag to not create this column, but for now, I will drop it from training and Kaggle.\n",
    "    df_train.drop(columns=['SinceSprayed'], inplace=True)\n",
    "    df_kaggle.drop(columns=['SinceSprayed'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:#3b748a'>*This needs some cleanup if there is time.* We spray on ten days. For each one,what are the areas that we spray that date? Which traps are near there?</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>2011-08-29 : Nothing good</span></li>\n",
    "    <li><span style='color:#4095b5'>2011-09-07 : 1 set</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-07-17 : 3 sets, 2 good</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-07-25 : 1 set</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-08-08 : 1 set</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-08-15 : 2 sets</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-08-16 : 2 sets, 1 good</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-08-22 : 2 sets</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-08-29 : 2 sets</span></li>\n",
    "    <li><span style='color:#4095b5'>2013-09-05 : 2 sets</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 95 traps sprayed on 2011-08-29 00:00:00.\n",
      "There are 1573 traps sprayed on 2011-09-07 00:00:00.\n",
      "There are 2202 traps sprayed on 2013-07-17 00:00:00.\n",
      "There are 1607 traps sprayed on 2013-07-25 00:00:00.\n",
      "There are 1195 traps sprayed on 2013-08-08 00:00:00.\n",
      "There are 2668 traps sprayed on 2013-08-15 00:00:00.\n",
      "There are 141 traps sprayed on 2013-08-16 00:00:00.\n",
      "There are 1587 traps sprayed on 2013-08-22 00:00:00.\n",
      "There are 2302 traps sprayed on 2013-08-29 00:00:00.\n",
      "There are 924 traps sprayed on 2013-09-05 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "# Which days do we spray?\n",
    "spray_dates = list(set(df_spray['Date']))\n",
    "spray_dates.sort()\n",
    "\n",
    "epsilon = .01\n",
    "spray = dict()\n",
    "for d in spray_dates:\n",
    "    df_temp = df_spray[df_spray['Date'] == d]\n",
    "    print(\"There are {} traps sprayed on {}.\".format(df_temp.shape[0], d))\n",
    "    \n",
    "    # For dates that have dispersed spraying, this is a terrible metric!\n",
    "    df_loc = df_spray[df_spray['Date'] == d]\n",
    "    min_lat = min(df_loc['Latitude'])\n",
    "    max_lat = max(df_loc['Latitude'])\n",
    "    min_lon = min(df_loc['Longitude'])\n",
    "    max_lon = max(df_loc['Longitude'])\n",
    "    \n",
    "    df_temp = df_traps[df_traps['Latitude'] < max_lat + epsilon]\n",
    "    df_temp = df_temp[df_temp['Latitude'] > min_lat - epsilon]\n",
    "    df_temp = df_temp[df_temp['Longitude'] < max_lon + epsilon]\n",
    "    df_temp = df_temp[df_temp['Longitude'] > min_lon - epsilon]\n",
    "    \n",
    "    traps = list(set(df_temp.index))\n",
    "    if len(traps) > 0:\n",
    "        spray[d] = traps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Determine dates that each trap was emptied (aka observed).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add days since emptied to each observation/Kaggle prediction\n",
    "\n",
    "# Gather the dates each trap was observed\n",
    "obsv_dates = []\n",
    "for t in df_traps.index:\n",
    "    dates_train = set(df_train.loc[df_train[\"Trap\"] == t,\"Date\"])\n",
    "    dates_kaggle = set(df_kaggle.loc[df_kaggle[\"Trap\"] == t,\"Date\"])\n",
    "    obsv_dates.append(dates_train.union(dates_kaggle))\n",
    "df_traps[\"ObsvDates\"] = obsv_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Determine # days since trap was emptied for each observation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"SinceEmptied\"] = 30\n",
    "for i in range(df_train.shape[0]):\n",
    "    trap = df_train.loc[i,\"Trap\"]\n",
    "    date = df_train.loc[i,\"Date\"]  \n",
    "    obsv_dates = [d for d in df_traps.loc[trap,\"ObsvDates\"] if d < date]\n",
    "    if obsv_dates:\n",
    "        elapsed = max(30,(date - max(obsv_dates)).days)\n",
    "        df_train.loc[i,\"SinceEmptied\"] = elapsed\n",
    "\n",
    "df_kaggle[\"SinceEmptied\"] = 100\n",
    "for i in range(df_kaggle.shape[0]):\n",
    "    trap = df_kaggle.loc[i,\"Trap\"]\n",
    "    date = df_kaggle.loc[i,\"Date\"]  \n",
    "    obsv_dates = [d for d in df_traps.loc[trap,\"ObsvDates\"] if d < date]\n",
    "    if obsv_dates:\n",
    "        elapsed = max(30,(date - max(obsv_dates)).days)\n",
    "        df_kaggle.loc[i,\"SinceEmptied\"] = elapsed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns to create a DataFrame from the full training set\n",
    "df_train_small = df_train.copy()\n",
    "df_train_small[y_count_label] = y_count\n",
    "df_train_small[y_wnv_label] = y_wnv\n",
    "df_train_small.drop(columns=['Latitude','Longitude','Week'], inplace=True)\n",
    "\n",
    "\n",
    "for date,traps in spray.items():\n",
    "    min_date = date - timedelta(days=100)\n",
    "    max_date = date + timedelta(days=100)\n",
    "    df_train_area = df_train_small[df_train_small[\"Trap\"].isin(traps)].copy()\n",
    "    df_train_area.drop(columns='Trap',inplace=True)\n",
    "    df_train_area = df_train_area[df_train_area['Date'] >= min_date].copy()\n",
    "    df_train_area = df_train_area[df_train_area['Date'] <= max_date].copy()\n",
    "    df_train_area = df_train_area.groupby(['Date'], as_index=False).sum().reindex()\n",
    "    df_train_area['WnvPresent'] = (df_train_area['WnvPresent'] > 0).astype(int)\n",
    "    dates = list(df_train_area.loc[(df_train_area['WnvPresent'] > 0),\"Date\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(figsize=(10, 20))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(str(date))\n",
    "    df_train_area.plot(x='Date', y='NumMosquitos', c=colors[0], marker='o', label = \"Number of mosquitos\", ax=ax);\n",
    "    ax.axvline(x=date, c='r', label=\"Spray date\")\n",
    "    label = True\n",
    "    for w in dates:\n",
    "        if label:\n",
    "            ax.axvline(x=w, c=colors[5], linestyle=\"dashed\", label=\"WNV Present\")\n",
    "            label = False\n",
    "        ax.axvline(x=w, c=colors[5], linestyle=\"dashed\")\n",
    "    ax.set_xlabel('')    \n",
    "    ax.set_ylabel('')\n",
    "    ax.legend(); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Days since last emptied</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Since there are traps in the test set but not in the train set, we need to make some inferences. We chose to start by clustering the traps.</span></li>\n",
    "    <li><span style='color:#4095b5'>Set the maximum \"Since emptied\" to be 365.</span></li>\n",
    "    <li><span style='color:#4095b5'>There must be a better way to slice the DataFrames....</span></li>\n",
    "    <li><span style='color:#4095b5'>Doesn't seem to help right now, but keeping it in case we create something else that makes it so this helps.</span></li>\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trap, calculate days since it was emptied\n",
    "# There must be a more elegant way to do this using slicing, but I couldn't figure it out quickly.\n",
    "\n",
    "do_days_since_empty = False\n",
    "if do_days_since_empty:\n",
    "    df_traps = pd.DataFrame(list(set(df_train['Trap']) | set(df_kaggle['Trap'])), columns=['Trap'])\n",
    "    df_traps\n",
    "\n",
    "    traps = list(df_traps['Trap'])\n",
    "    dates = []\n",
    "    for t in traps:\n",
    "        dates_train = set(df_train.loc[df_train['Trap'] == t, 'Date'])\n",
    "        dates_kaggle = set(df_kaggle.loc[df_kaggle['Trap'] == t, 'Date'])\n",
    "        dates.append(dates_train | dates_kaggle)\n",
    "\n",
    "    df_traps['Dates'] = dates\n",
    "    df_traps.set_index(['Trap'], inplace=True)\n",
    "\n",
    "    # Now for each train and kaggle record, add a column of last day checked\n",
    "    emptied = []\n",
    "    for i in range(df_train.shape[0]):\n",
    "        trap = df_train.loc[i,\"Trap\"]\n",
    "        date = df_train.loc[i,\"Date\"]   \n",
    "        dates = [i for i in set(df_traps.loc[trap][\"Dates\"]) if i < date]\n",
    "        if len(dates) > 0:\n",
    "            emptied_i = min((date - max(dates)).days,365)\n",
    "        else:\n",
    "            emptied_i = 365\n",
    "        emptied.append(emptied_i)\n",
    "\n",
    "    df_train[\"Emptied\"] = emptied\n",
    "\n",
    "    emptied = []\n",
    "    for i in range(df_kaggle.shape[0]):\n",
    "        trap = df_kaggle.loc[i,\"Trap\"]\n",
    "        date = df_kaggle.loc[i,\"Date\"]   \n",
    "        dates = [i for i in set(df_traps.loc[trap][\"Dates\"]) if i < date]\n",
    "        if len(dates) > 0:\n",
    "            emptied_i = min((date - max(dates)).days,365)\n",
    "        else:\n",
    "            emptied_i = 365\n",
    "        emptied.append(emptied_i)\n",
    "\n",
    "    df_kaggle[\"Emptied\"] = emptied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Cluster the traps</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Traps in train (orange).</span>\n",
    "    <li><span style='color:#4095b5'>Traps in train with West Nile present (blue).</span>\n",
    "    <li><span style='color:#4095b5'>Traps in Kaggle test (purple).</span>\n",
    "</ul>\n",
    "<img src=\"../images/trap-map.jpg\" alt=\"traps\" alt=\"Trap locations\" width=400/>\n",
    "<center><span style='color:#4095b5'>Map of traps and West Nile</span></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_clusters = False\n",
    "\n",
    "if do_clusters:\n",
    "    # Combine train and test traps\n",
    "    traps = df_train[['Latitude', 'Longitude']].copy()\n",
    "    train_rows = traps.shape[0]\n",
    "    traps = traps.append(df_kaggle[['Latitude', 'Longitude']])\n",
    "\n",
    "    # Call k-means to cluster the traps\n",
    "    kmeans = KMeans(n_clusters=50, random_state=1929)\n",
    "    model = kmeans.fit(traps)\n",
    "    centroids = pd.DataFrame(model.cluster_centers_, columns = ['x1', 'x2'])\n",
    "\n",
    "    # Plot the traps and centroids\n",
    "\n",
    "    ax = traps.plot(    \n",
    "        kind=\"scatter\", \n",
    "        y='Latitude', x='Longitude',\n",
    "        figsize=(10,8),\n",
    "        c = colors[3]\n",
    "    )\n",
    "\n",
    "    centroids.plot(\n",
    "        kind=\"scatter\", \n",
    "        y=\"x1\", x=\"x2\", \n",
    "        marker=\"*\", s=550,\n",
    "        color = colors[1], \n",
    "        ax=ax\n",
    "    );\n",
    "\n",
    "    # Add the cluster information to each row\n",
    "    traps['Cluster'] = kmeans.labels_\n",
    "    df_train['Cluster'] = (traps['Cluster'][0:train_rows]).astype(object)\n",
    "    df_kaggle['Cluster'] = (traps['Cluster'][train_rows:]).astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/clusters.jpg\" alt=\"clusters\" alt=\"Clusters\" width=500/>\n",
    "<center><span style='color:#4095b5'>Clusters calculated with KMeans</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Create a table of Number of Mosqitos per week</span>\n",
    "\n",
    "<span style='color:#52aec9'>Useful for plotting and mapping and feature engineering.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mosquito_cols = ['Year', 'Week']\n",
    "df_num_mosquitos = df_train[num_mosquito_cols].copy()\n",
    "df_num_mosquitos[y_count_label] = y_count\n",
    "df_num_mosquitos = df_num_mosquitos.groupby(by = ['Year','Week'], as_index=False).sum()\n",
    "print(\"Number of Weeks with mosquito counts: {}\".format(df_num_mosquitos.shape[0]))\n",
    "df_num_mosquitos.head()\n",
    "# df_num_mosquitos.to_csv('../data/weekly_num_mosq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <span style='color:#3b748a'>Function to make dummies</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make dummies for the categorical data\n",
    "def make_dummies(train, test, cols):\n",
    "\n",
    "    train = train[X_cols].copy()\n",
    "    test = test[X_cols].copy()\n",
    "    \n",
    "    train = pd.get_dummies(train)\n",
    "    test = pd.get_dummies(test)\n",
    "\n",
    "    # Get dummies could leave us with mismatched columns\n",
    "    # Make sure we have mathcing columns in the train and kaggle DataFrames\n",
    "\n",
    "    cols_train = train.columns\n",
    "    cols_test = test.columns\n",
    "\n",
    "    for c in cols_train:\n",
    "        if c not in cols_test:\n",
    "            test[c] = 0\n",
    "\n",
    "    for c in cols_test:\n",
    "        if c not in cols_train:\n",
    "            train[c] = 0\n",
    "\n",
    "    columns = sorted(train.columns)\n",
    "    train = train[columns]\n",
    "    test = test[columns]\n",
    "\n",
    "    if train.shape[1] != test.shape[1]:\n",
    "        print(\"Train and Test don't have same # columns: {} {}\".format(train.shape[1], test.shape[1]))\n",
    "\n",
    "    # Having made dummies, we now have lots and lots of columns\n",
    "    print(\"There are {} columns and {} categorial columns.\"\n",
    "          .format(train.shape[1],\n",
    "                  train.select_dtypes([np.object]).shape[1]))\n",
    "    \n",
    "    return [train, test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#37535e'><b>Feature engineering</b></span><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Traps</b></span><br />\n",
    "<span style='color:#3b748a'>For each trap, we calculated two sets: the days it was emptied and the days it was sprayed. The first one is fairly straightforward to compute from the observations. The second took more work as we needed to create a distance metric to determine if a trap was in an area covered by spraying. From these, we were able to add columns to the observations and predictions: Days since sprayed (Since_sprayed) and Days since emptied (Since_emptied).</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Clusters</b></span><br />\n",
    "<span style='color:#3b748a'>Considering how account for the fact that we had to predict data for traps not in the observation set, we decided to see if we could create a category column in the observation and prediction data for \"clusters\" of traps. An elegant process and map, but unfortunately did not appear to give us any extra benefit in the end. The latitude and longitude measures were sufficient.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Make dummies</b></span><br />\n",
    "<span style='color:#3b748a'>While much of the data is numerical, there is some categorical data (Species, in particular) that we needed to make dummy columns for. As always, we had to ensure that both the observations and predictions had the same dummies.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step4\"></a>\n",
    "## <span style='color:#37535e'>Model the data</span>\n",
    " <span style='color:#3b748a'>For each record in the test set, you should predict a real-valued probability that WNV is present.</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>First, we have to predict HOW MANY mosquitoes of each species will be in a trap on a given date.</span></li>\n",
    "    <li><span style='color:#4095b5'>Then we have to predict the probablity that there will be West Nile virus present based on those counts.</span></li>\n",
    "</ul> \n",
    "\n",
    "### <span style='color:#3b748a'>We had two models:</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>For both steps, we tried a Grid Search on a Pipeline.</span></li>\n",
    "<li><span style='color:#4095b5'>Computing a dataframe with empirical probalities of WNV | # in trap &amp; species. See <a href=\"#step7\"><span style='color:#4095b5'>the section below</span></a>.</span></li>\n",
    "</ul>\n",
    "\n",
    "### <span style='color:#3b748a'>The MASSIVE Pipeline</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>The Pipeline function takes a set of features and a model and runs grid search over their parameters on the train/test data for the specified model.</span></li>\n",
    "    <li><span style='color:#4095b5'>Adjustment of the parameter ranges is not automated at this time. Each time it runs, we check to see if a parameter bound has been hit and adjust the value ranges.</span></li>\n",
    "    <li><span style='color:#4095b5'>The function returns information about the best model, but not the model itself. Perhaps to be included in the future.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipline(items, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Add a pipe, add a param !\n",
    "    pipe_items = {\n",
    "        'ss' : StandardScaler(),\n",
    "        'pf' : PolynomialFeatures(),\n",
    "\n",
    "        'lr' : LinearRegression(),\n",
    "        'rd' : Ridge(),\n",
    "        'la' : Lasso(),\n",
    "        'en' : ElasticNet(), \n",
    "        'gr' : GaussianProcessRegressor(),\n",
    "        'rf' : RandomForestRegressor(),\n",
    "        'gb' : GradientBoostingRegressor(),\n",
    "        'ab' : AdaBoostRegressor(),\n",
    "        'svm' : SVR(),\n",
    "        'knn' : KNeighborsRegressor(),\n",
    "        \n",
    "        'lgr' : LogisticRegression(),\n",
    "        'rfc' : RandomForestClassifier(),\n",
    "        'gbc' : GradientBoostingClassifier(),\n",
    "        'abc' : AdaBoostClassifier(),\n",
    "        'svc' : SVC(),\n",
    "        'knnc' : KNeighborsClassifier()\n",
    "\n",
    "    }\n",
    "\n",
    "    # Include at least one param for each pipe item\n",
    "    param_items = {\n",
    "        'ss' : {\n",
    "            'ss__with_mean' : [False]\n",
    "        },\n",
    "        'pf' : {\n",
    "            'pf__degree' : [2]\n",
    "        },\n",
    "        'lr' : {\n",
    "            'lr__n_jobs' : [1]\n",
    "        },\n",
    "        'rd' : {\n",
    "             'rd__alpha' : [55.0, 60.0, 65.0]\n",
    "        },\n",
    "        'la' : {\n",
    "             'la__alpha' : [0.005, 0.0075, 0.01], \n",
    "             'la__max_iter' : [100000]\n",
    "        },\n",
    "        'en' : {\n",
    "             'en__alpha' : [0.01, 0.02, 0.4], \n",
    "             'en__l1_ratio' : [.8, 1, 1.2]\n",
    "        },\n",
    "        'gr' : {\n",
    "            'gr__alpha' : [1, 0.1]\n",
    "        },\n",
    "        'rf' : {\n",
    "            'rf__n_estimators' : [7, 8, 9]\n",
    "        },\n",
    "        'gb' : {\n",
    "            'gb__n_estimators' : [325, 330, 335]\n",
    "        },\n",
    "        'ab' : {\n",
    "            'ab__n_estimators' : [65, 70, 75]\n",
    "        },\n",
    "        'svm' : {\n",
    "            'svm__kernel' : ['linear','poly']\n",
    "        },\n",
    "        'knn' : {\n",
    "            'knn__n_neighbors' : [3, 4, 5, 6]\n",
    "        },\n",
    "        'lgr' : {\n",
    "            'lgr__C' : [.04, .05, .06],\n",
    "            'lgr__penalty' : ['l1','l2']\n",
    "        },\n",
    "        'rfc' : {\n",
    "            'rfc__n_estimators' : [7, 8, 9, 10]\n",
    "        },\n",
    "        'gbc' : {\n",
    "            'gbc__n_estimators' : [35, 40, 45]\n",
    "        },\n",
    "        'abc' : {\n",
    "            'abc__n_estimators' : [80, 90, 100]\n",
    "        },\n",
    "        'svc' : {\n",
    "            'svc__kernel' : ['linear','poly']\n",
    "        },\n",
    "        'knnc' : {\n",
    "            'knnc__n_neighbors' : [35, 40, 45, 50]\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    # Create the parameters for GridSearch\n",
    "    params = dict()\n",
    "    for i in items:\n",
    "        for p in param_items[i]:\n",
    "            params[p] = param_items[i][p]\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipe_list = [(i,pipe_items[i]) for i in items]\n",
    "    print(\"Using:\")\n",
    "    for p in pipe_list:\n",
    "        print(\"\\t\" + str(p[1]).split('(')[0])\n",
    "    pipe = Pipeline(pipe_list)\n",
    "\n",
    "    # Grid search\n",
    "    gs = GridSearchCV(pipe, param_grid=params, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Print the results\n",
    "    train_params = gs.best_params_\n",
    "    train_score = gs.best_score_\n",
    "    y_test_hat = gs.predict(X_test)\n",
    "    test_score = gs.score(X_test, y_test)\n",
    "\n",
    "    for k in train_params:\n",
    "        print(\"{}: {}\".format(k,train_params[k]))\n",
    "\n",
    "    print(\"Train score: {} Test score {}\".format(train_score, test_score))\n",
    "    print(\"\")\n",
    "\n",
    "    return train_score, test_score, y_test_hat, train_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Prepare for REGRESSION to predict <span style=\"font-family:monospace\">NumMosquitos</span></span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Use a subest of columns: The columns are <span style=\"font-family:monospace\">['Week', 'Year', 'Species', 'Latitude', 'Longitude']</span></span></li>\n",
    "    <li><span style='color:#4095b5'>Make dummies on the columns (only <span style=\"font-family:monospace\">'Species'</span> at the moment).</span></li>\n",
    "    <li><span style='color:#4095b5'>Do a train/test split on the training data.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a few features\n",
    "X_cols = list(df_train.columns)\n",
    "X_cols.remove('Date')\n",
    "X_cols.remove('Trap')\n",
    "\n",
    "if do_days_since_empty:\n",
    "    X_cols.remove('Emptied')\n",
    "\n",
    "if do_clusters:\n",
    "    X_cols.remove('Latitude')\n",
    "    X_cols.remove('Longitude')\n",
    "    \n",
    "print(\"The columns are {}\".format(X_cols))\n",
    "[X_cols_train, X_cols_kaggle] = make_dummies(df_train, df_kaggle, X_cols)\n",
    "\n",
    "# Test/train split of \"full training\" data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cols_train, y_count, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Call the pipeline to use REGRESSION to predict <span style=\"font-family:monospace\">NumMosquitos</span></span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Choose a regression model.</span></span></li>\n",
    "    <li><span style='color:#4095b5'>Use <span style=\"font-family:monospace\">StandardScaler</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>Update params values based on grid search and repeat (not automated).</span>       <li><span style='color:#4095b5'>Fudge the predicted data -- <span style=\"font-family:monospace\">NumMosquitos</span> is non-negative and if duplicate rows in Kaggle test data, all but last row should have 50 mosquitos.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression models\n",
    "# 'lr' : LinearRegression(),\n",
    "# 'rd' : Ridge(),\n",
    "# 'la' : Lasso(),\n",
    "# 'en' : ElasticNet(), \n",
    "# 'gr' : GaussianProcessRegressor(),\n",
    "# 'rf' : RandomForestRegressor(),\n",
    "# 'gb' : GradientBoostingRegressor(),\n",
    "# 'ab' : AdaBoostRegressor(),\n",
    "# 'svm' : SVR(),\n",
    "# 'knn' : KNeighborsRegressor(),\n",
    "\n",
    "models = ['lr','rd','la','en','rf','gb','ab','knn'] # 'gr',svm']\n",
    "\n",
    "model_solns = {}\n",
    "for m in models:\n",
    "    pipe_items = ['ss', m]\n",
    "    [train_score, test_score, y_test_hat, best_params] = run_pipline(pipe_items,\n",
    "                                                            X_train, X_test, \n",
    "                                                            y_train, y_test)\n",
    "    model_solns[idx] = {'model': m, \n",
    "                        'train_score': train_score, 'test_score': test_score, \n",
    "                        'best_params': best_params, 'y_test_hat' : y_test_hat}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Choose best REGRESSION to predict <span style=\"font-family:monospace\">NumMosquitos</span></span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>The best regression model is <span style=\"font-family:monospace\">GradientBoostingRegressor</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>Using the best model, predict the <span style=\"font-family:monospace\">NumMosquitos</span> for the Kaggle test set.</span></li>\n",
    "    <li><span style='color:#4095b5'>Do a little post-processing to the predicted counts.</span></li>\n",
    "</ul>\n",
    "\n",
    "#### <span style='color:#4095b5'>Fit the best model to the training set.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('gb', GradientBoostingRegressor())\n",
    "])\n",
    "params_grid_cv = {\n",
    "    'ss__with_mean' : [False],\n",
    "    'gb__n_estimators' : [325, 330, 335]\n",
    "}\n",
    " \n",
    "gs = GridSearchCV(pipe, param_grid=params_grid_cv, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sales price of the Kaggle data\n",
    "y_hat = gs.predict(X_test)\n",
    "\n",
    "print(\"Train score: {} Test score: {}\".format(gs.score(X_train,y_train),gs.score(X_test,y_test)))\n",
    "\n",
    "# With aggregating observation rows:\n",
    "# Train score: 0.9837199209535019 Test score: 0.9560608932255188\n",
    "\n",
    "# Train score: 0.5849628964570315 Test score: 0.5677847042206758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Fit the model to the Kaggle set and add the predictions to the Kaggle test DataFrame.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit full train data to predict kaggle\n",
    "# Didn't help\n",
    "# gs.fit(X_cols_train,y_count)\n",
    "\n",
    "# Now predict how many mosquitoes will be in each of the kaggle tests given this\n",
    "df_train[y_count_label] = y_count\n",
    "df_kaggle[y_count_label] = gs.predict(X_cols_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Duplicate rows should have 50 mosquitos.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 in all duplicates except the \"last\" duplicate\n",
    "# Replace negative values with 0\n",
    "\n",
    "# Remove the Id\n",
    "cols = list(df_kaggle.columns)\n",
    "cols.remove('Id')\n",
    "\n",
    "# Indices of duplicates for the first occurrence\n",
    "duplicate_indices = df_kaggle[df_kaggle.duplicated(cols) == True].index\n",
    "\n",
    "# There are 50 mosquitos in the \"previous\" record\n",
    "for i in duplicate_indices:\n",
    "    df_kaggle.loc[i-1,y_count_label] = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>The number of mosquitos should be non-negative.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.loc[(df_kaggle[y_count_label] < 0), y_count_label] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Prepare for CLASSIFICATION to predict if West Nile is present given the <span style=\"font-family:monospace\">NumMosquitos</span>.</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Use a subest of columns: The columns are <span style=\"font-family:monospace\">['Week', 'Species', 'Latitude', 'Longitude', 'Year', 'NumMosquitos']</span></span></li>\n",
    "    <li><span style='color:#4095b5'>Make dummies on the columns (only <span style=\"font-family:monospace\">'Species'</span> at the moment).</span></li>\n",
    "    <li><span style='color:#4095b5'>Do a train/test split on the training data.</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a few features\n",
    "X_cols = list(df_train.columns)\n",
    "X_cols.remove('Date')\n",
    "X_cols.remove('Trap')\n",
    "# X_cols.remove('Year')\n",
    "\n",
    "if do_clusters:\n",
    "    X_cols.remove('Latitude')\n",
    "    X_cols.remove('Longitude')\n",
    "\n",
    "print(\"The columns are {}\".format(X_cols))\n",
    "[X_cols_train, X_cols_kaggle] = make_dummies(df_train, df_kaggle, X_cols)\n",
    "\n",
    "# Test/train split of \"full training\" data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cols_train, y_wnv, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#3b748a'>Call the pipeline to use CLASSIFICATION to predict if West Nile is present given the <span style=\"font-family:monospace\">NumMosquitos</span>.</span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>Choose a classification model.</span></span></li>\n",
    "    <li><span style='color:#4095b5'>Use <span style=\"font-family:monospace\">StandardScaler</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>Update params values based on grid search and repeat (not automated).</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification models\n",
    "#         'lgr' : LogisticRegression(),\n",
    "#         'rfc' : RandomForestClassifier(),\n",
    "#         'gbc' : GradientBoostingClassifier(),\n",
    "#         'abc' : AdaBoostClassifier(),\n",
    "#         'svc' : SVC(),\n",
    "#         'knnc' : KNeighborsClassifier()\n",
    "\n",
    "# Decide what to put into the pipline, grid searh, and save the \"best\" for each grid search\n",
    "models = ['lgr','rfc','gbc','abc','knnc']\n",
    "# other = ['pf','ss']\n",
    "\n",
    "# After some initial tests, these seem like the best to pursue further\n",
    "# models = ['lgr']\n",
    "\n",
    "model_solns = {}\n",
    "for m in models:\n",
    "    pipe_items = ['ss', m]\n",
    "    [train_score, test_score, y_test_hat, best_params] = run_pipline(pipe_items,\n",
    "                                                            X_train, X_test, \n",
    "                                                            y_train, y_test)\n",
    "    model_solns[idx] = {'model': m, \n",
    "                        'train_score': train_score, 'test_score': test_score, \n",
    "                        'best_params': best_params, 'y_test_hat' : y_test_hat}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step5\"></a>\n",
    "## <span style='color:#37535e'>Evaluate the model</span>\n",
    "\n",
    "### <span style='color:#3b748a'>Choose best CLASSIFICATION to predict <span style=\"font-family:monospace\">NumMosquitos</span></span>\n",
    "<ul>\n",
    "    <li><span style='color:#4095b5'>The best classification model is <span style=\"font-family:monospace\">LogisticRegression</span>.</span></li>\n",
    "    <li><span style='color:#4095b5'>Using the best model, predict the probability of West Nile Virus.</span></li>\n",
    "</ul>\n",
    "\n",
    "#### <span style='color:#4095b5'>Fit the model to the training set.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lgr', LogisticRegression())\n",
    "])\n",
    "params_grid_cv = {\n",
    "    'ss__with_mean' : [False],\n",
    "    'lgr__C' : [.04, .05, .06],\n",
    "    'lgr__penalty' : ['l1','l2']\n",
    "}\n",
    "\n",
    "        \n",
    "gs = GridSearchCV(pipe, param_grid=params_grid_cv, verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sales price of the Kaggle data\n",
    "y_test_hat = gs.predict(X_test)\n",
    "y_test_proba = gs.predict_proba(X_test)\n",
    "df_test_proba = pd.DataFrame(y_test_proba)\n",
    "y_test_proba = df_test_proba[1]\n",
    "\n",
    "print(\"Train score: {} Test score: {}\".format(gs.score(X_train,y_train),gs.score(X_test,y_test)))\n",
    "print(\"ROC AUC score: {}\".format(roc_auc_score(y_test, y_test_proba)))\n",
    "\n",
    "# Train score: 0.947074501840335 Test score: 0.9489912447658927\n",
    "# ROC AUC score: 0.779049996707198"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#37535e'><b>Modeling</b></span><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>The main objective</b></span>\n",
    "<span style='color:#3b748a'>For each entry in the predictions dataset, we need to predict the probability that West Nile will be observed.</span>\n",
    "\n",
    "<span style='color:#3b748a'><b>Model 1: Regression/Classification with post-processing</b></span><br />\n",
    "<span style='color:#3b748a'>The initial idea for a model was to break it into two steps: first predict how many of each species would be in a trap for each entry in the predictions data set, then from that predict the probability of West Nile.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'>For the first model, we took a subset of the features('Week', 'Year', 'Species', 'Latitude', 'Longitude'), did a train/test split on the observed data, and then ran a grid search including scaling using eight different regression algorithms on the data in order to predict HOW MANY mosquitos of each species will be present. The best regressor was the <span style=\"font-family:monospace\">GradientBoostingRegressor</span>. Once a model was fit and the parameters tuned, we then made a prediction.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'>We then tuned this mosquito count prediction in two ways. First, we rounded up to 0 any negative predictions. Second, we made the observation that there were 1533 duplicate rows in the Kaggle test data set. ASSUMING, that this is for the same reasons there were duplicate rows in the observation set, we set the predicted number of mosquitos to be 50 for the duplicate row (except for the last duplicate in each repetition.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'>Given our new \"feature\" of \"Number of Mosquitos\", we then took a subset of the features('Week', 'Year', 'Species', 'Latitude', 'Longitude', 'NumMosquitos'), did a train/test split on the observed data, and then ran a grid search including scaling using six different classification algorithms on the data in order to predict the PRESENCE of West Nile Virus for each Kaggle test observation. The best classification was <span style=\"font-family:monospace\">LogiticRegression</span>. Once a model was fit and the parameters tuned, we then make a prediction on the probability that for the date/trap/species there will be a positive test for West Nile Virus.</span>\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'>We then tuned this probability prediction by setting the prediction to 0.0 for all species OTHER that the three in which West Nile was observed. (This is done below right now, but could be moved up.)</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>This gave an AUC ROC of 0.78. On Kaggle, the scores are 0.72432 and 0.73532. (../data/model_preds_2018-09-20 17/01/32.671403.csv)\n",
    "</span>\n",
    "\n",
    "<br /><br />\n",
    "\n",
    "<span style='color:#3b748a'><b>Model 2: Percentage model</b></span><br />\n",
    "<span style='color:#3b748a'>The percentage model leverages the modeling done above with respect to the prediction of the number of mosquitoes present in the Kaggle test traps.  We then sought to create data from our data files so that we could look up the probability of the presence of West Nile given the species found in the that trap and the number of mosquitoes present in the trap.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>\n",
    "There are three species of mosquitoes that carried West Nile virus in our observations.  We summed the data available to create a matrix of the number of observations where the columns are the species and the rows are the number of mosquitoes found in the trap.  We then created a second, similar matrix except that the observations where only the times that West Nile virus was present.  The final matrix is the division of the second by the first.  This gives the probability of finding West Nile virus in a trap given the number of mosquitoes in the trap of a certain species.</span>\n",
    "<br /><br />\n",
    "<span style='color:#3b748a'>\n",
    "The results were choppy by number of mosquitoes but generally followed an upward trend.  For the three species where West Nile virus was present, we then used linear regression tools to smooth the probabilities (least squares line of best fit).  By linking the Kaggle test data (species plus projected mosquitoes using GradientBosstingRegression) to these smoothed probabilities, we could complete a submission file.\n",
    "Using this final, smoothed result gave an AUC ROC of 0.71 (../data/sub0007.csv).</span>\n",
    "<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step6\"></a>\n",
    "## <span style='color:#37535e'>Answer the question</span>\n",
    "###  <span style='color:#3b748a'>Output the results to upload to Kaggle.</span>\n",
    "\n",
    "#### <span style='color:#4095b5'>Fit the model to the Kaggle set and add the predictions (probability of West NIle) to the Kaggle test DataFrame.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit full train data to predict kaggle\n",
    "# Didn't help\n",
    "# gs.fit(X_cols_train,y_wnv)\n",
    "\n",
    "y_kaggle_proba = gs.predict_proba(X_cols_kaggle)\n",
    "y_kaggle = list(y_kaggle_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for Kaggle submission\n",
    "# Make the ID the index\n",
    "df_kaggle['WnvPresent'] = y_kaggle\n",
    "df_kaggle.loc[(df_kaggle['Species'].isin(species_wnv) == False), 'WnvPresent'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kaggle = df_kaggle['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.set_index(\"Id\", inplace=True)\n",
    "df_soln = pd.DataFrame(df_kaggle.index)\n",
    "df_soln['WnvPresent'] = y_kaggle\n",
    "\n",
    "# Predict no Wnv if not one of three species\n",
    "df_soln.set_index(['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predicted Kaggle solution out to a file\n",
    "now = str(datetime.now())\n",
    "f'predictions_{now}'\n",
    "df_soln.to_csv(f'../data/model_preds_{now}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<a name=\"step7\"></a>\n",
    "## <span style='color:#37535e'>VII. More modeling</span>\n",
    "\n",
    "<span style='color:#3b748a'>We wanted to merge the notebooks, but it was taking too long. Other work is included here instead.</span>\n",
    "\n",
    "### <span style='color:#3b748a'>Computing a dataframe with empirical probalities of WNV | # in trap &amp; species</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train = pd.read_csv('../data/train.csv')\n",
    "kaggle_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X_k_train = kaggle_train[['Date', 'Species', 'Trap', 'Latitude', 'Longitude', 'NumMosquitos','WnvPresent']].copy()\n",
    "X_cols = list(X_k_train.columns.drop(['WnvPresent','NumMosquitos']))\n",
    "\n",
    "X_k_train['Date'] = pd.to_datetime(kaggle_train['Date'])\n",
    "\n",
    "X_k_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = list(set(X_k_train['Species']))\n",
    "df = pd.DataFrame(0, index = range(51), columns = spec)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df(df_in, species, yn_var):\n",
    "    df_in.loc[yn_var,species] += 1\n",
    "    return(df_in)\n",
    "\n",
    "for each in range(len(X_k_train)):  \n",
    "    df = add_to_df(df, X_k_train.loc[each,'Species'], X_k_train.loc[each,'NumMosquitos'])\n",
    "\n",
    "df.head()       # number of occurance of species / trap in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df2(df_in, species, NumM, Wnv):\n",
    "    df_in.loc[NumM,species] += Wnv\n",
    "    return(df_in)\n",
    "\n",
    "df2 = pd.DataFrame(0, index = range(51), columns = spec)\n",
    "for each in range(len(X_k_train)):  \n",
    "    df2 = add_to_df2(df2, X_k_train.loc[each,'Species'], X_k_train.loc[each,'NumMosquitos'],X_k_train.loc[each,'WnvPresent'])\n",
    "\n",
    "df2.head()           # number of WNV Present occurances by Species and Number in trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "for i in range(len(df2)):\n",
    "    for j in df2.columns:\n",
    "        if df.loc[i,j] == 0:\n",
    "            df3.loc[i,j] = 0\n",
    "        else:\n",
    "            df3.loc[i,j] = df2.loc[i,j] / df.loc[i,j]\n",
    "            \n",
    "df3.head()     # Empirical probabilities of WNV present given Species and Number of Mosquitos in trap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Creating a regression to smooth the probabilities given species &amp; trap number</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(range(0,51))\n",
    "y = df3['CULEX PIPIENS']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X,y)\n",
    "\n",
    "\n",
    "probs = pd.DataFrame(0, index = range(51), columns = set(kaggle_test['Species']))\n",
    "prob = []\n",
    "for each in X:\n",
    "    prob.append(each*slope+intercept)\n",
    "\n",
    "    prob[0] = 0\n",
    "probs['CULEX PIPIENS'] = prob\n",
    "\n",
    "y = df3['CULEX PIPIENS/RESTUANS']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X,y)\n",
    "prob = []\n",
    "for each in X:\n",
    "    prob.append(each*slope+intercept)\n",
    "prob[0] = 0\n",
    "probs['CULEX PIPIENS/RESTUANS'] = prob\n",
    "\n",
    "y = df3['CULEX RESTUANS']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X,y)\n",
    "prob = []\n",
    "for each in X:\n",
    "    prob.append(each*slope+intercept)\n",
    "prob[0] = 0\n",
    "probs['CULEX RESTUANS'] = prob\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Read projected mosquito by trap and species and match each projection data row with a probability</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.read_csv('../data/pred_mosq.csv')\n",
    "\n",
    "k['WnvPresent'] = 0\n",
    "\n",
    "for each in range(len(k)):\n",
    "    sp = k.loc[each, 'Species']\n",
    "    num = int(k.loc[each, 'NumMosquitos'])\n",
    "    k.loc[each, 'WnvPresent'] = probs.loc[num,sp]\n",
    "    if sp == 'UNSPECIFIED CULEX':\n",
    "        kaggle_test.loc[each, 'WnvPresent'] = .01\n",
    "\n",
    "out = k[['Id', 'WnvPresent']]\n",
    "out.to_csv('../data/sub007.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Make a couple of graphs for presentation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels as needed\n",
    "ax = df3['CULEX RESTUANS'].plot(kind='line', c='b', figsize = (12,8), label = 'Culex Restuans Raw')\n",
    "ax = probs['CULEX RESTUANS'].plot(kind='line', c='g', figsize = (12,8), label = 'Culex Restuans Smoothed')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.legend(loc = 'upper left', fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"avg_prec\"></a>\n",
    "### <span style='color:#4095b5'>Average precipitation calculations</span>\n",
    "\n",
    "<span style='color:#4095b5'>This produces a wonderful graphic!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../data/weather.csv', skipinitialspace=True)\n",
    "\n",
    "weather['Date'] = pd.to_datetime(weather['Date'])\n",
    "weather[weather['PrecipTotal'] =='M']\n",
    "weather.loc[117,'PrecipTotal'] = 0\n",
    "weather.loc[119,'PrecipTotal'] = 0\n",
    "\n",
    "weather['year'] = weather['Date'].dt.strftime('%Y')\n",
    "weather['week'] = weather['Date'].dt.strftime('%W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.to_numeric(weather['year']))\n",
    "df['week'] = pd.to_numeric(weather['week'])\n",
    "df['precip'] = pd.to_numeric(weather['PrecipTotal'].replace('  T',0))\n",
    "\n",
    "df_prec = (df.groupby(by = ['year','week']).mean())\n",
    "(df.groupby(by = ['year','week']).mean()).to_csv('../data/weekly_precip.csv')\n",
    "df_prec = df_prec.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('../data/train.csv')\n",
    "train = train_full[['Date', 'NumMosquitos']].copy()\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['year'] = train['Date'].dt.strftime('%Y')\n",
    "train['week'] = train['Date'].dt.strftime('%W')\n",
    "train['year'] = pd.to_numeric(train['year'])\n",
    "train['week'] = pd.to_numeric(train['week'])\n",
    "\n",
    "train = train.drop(['Date'], axis = 1)\n",
    "(train.groupby(by = ['year','week']).sum()).to_csv('../data/weekly_num_mosq.csv')\n",
    "\n",
    "df_numb = (train.groupby(by = ['year','week']).sum())\n",
    "df_numb = df_numb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merge = pd.merge(df_prec, df_numb, how='left', on=['year','week'])\n",
    "dropna_merge = full_merge.dropna().reset_index()\n",
    "dropna_merge.head()\n",
    "\n",
    "#fig = plt.figure(figsize = (12, 6))\n",
    "\n",
    "figsize=(20, 8)\n",
    "ax = dropna_merge['NumMosquitos'].plot(kind = 'line', c = 'r', figsize=figsize, label = 'Mosquitos')\n",
    "ax = (dropna_merge['precip']*10000).plot(kind = 'line', c = 'b', figsize=figsize, label = 'Rain')\n",
    "plt.axvline(17.5, c = 'grey', lw = 3, ymax = .95, label = \"Year Breaks ('07, '09, '11, '13)\")\n",
    "plt.axvline(34.5, c = 'grey', lw = 3, ymax = .95)\n",
    "plt.axvline(48.5, c = 'grey', lw = 3, ymax = .95)\n",
    "\n",
    "plt.axvline(45, c = 'g', lw = 1, ls = 'dashed', ymax = .95, label = 'Spray Dates')\n",
    "plt.axvline(46, c = 'g', lw = 1, ls = 'dashed', ymax = .95)\n",
    "plt.axvline(54, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "plt.axvline(55, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "plt.axvline(57, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "plt.axvline(58, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "plt.axvline(60, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "plt.axvline(61, c = 'g', lw = 1, ls = 'dashed', ymax = .65)\n",
    "\n",
    "\n",
    "plt.title('Weekly data showing Number of Mosquitoes Collected in Traps vs Average Daily Rainfall', fontsize = 20)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.legend(loc = 'upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step8\"></a>\n",
    "## <span style='color:#37535e'>Future investigations:</span>\n",
    "<span style=\"color:#3b748a\">Includes but not limited to:\n",
    "<ul>\n",
    "<li><span style=\"color:#3b748a\">Re-add dates checked column for each trap.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Clean up the calculation of Sprayed Date - so messy.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Re-add a column for time since last observation for each trap.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Check if every trap was checked on each date.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Improve distance calculation for determining if a trap was within the spraying radius</span></li>\n",
    "<br />\n",
    "<li><span style=\"color:#3b748a\">Investigate hours of daylight.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Explore the weather data more deeply. Dates, streaks, etc.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Dig further into spraying data as well.</span></li>\n",
    "<br />\n",
    "<li><span style=\"color:#3b748a\">Observations with zero of a species. Should we add an extra row just in case? Will that actaully add any new information?</span></li>\n",
    "<br />\n",
    "<li><span style=\"color:#3b748a\">Cleanup spray graphics.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Are there any interesting linear relationships?</span></li>\n",
    "<li><span style=\"color:#3b748a\">More graphs of spray and weather and mosquito information over time</span></li>\n",
    "<li><span style=\"color:#3b748a\">Include distribution of WNV and species over each summer.</span></li>\n",
    "<br />\n",
    "<li><span style=\"color:#3b748a\">Tune the regression/classification algorithms and add more?</span></li>\n",
    "<li><span style=\"color:#3b748a\">Try to fit ExtraTrees, Gamma GLM.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Investigate unbalanced data and how best to account for it.</span></li>\n",
    "<li><span style=\"color:#3b748a\">Extend the grid search to search over all combinations of regression/classifications for the two steps in the model.</span>\n",
    " <br />\n",
    "<li><span style=\"color:#3b748a\">Aggregate the observations to predict the # of mosquitos in a top, then split to predict probability of West Nile. If we aggregate, we lose some info. But if we don't aggregate, we run the risk of under-predicting the number of mosquitos. I think we should try aggregating to predict counts, then unaggregating to predict the presence\n",
    "</span></li>\n",
    "</ul>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"step9\"></a>\n",
    "## <span style='color:#37535e'>For reference or possible future use:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the hotspots\n",
    "def put_t_back(obs_in):\n",
    "    obs_in = str(obs_in)\n",
    "    if len(obs_in) == 1:\n",
    "        obs_out = 'T00'+obs_in\n",
    "    if len(obs_in) == 2:\n",
    "        obs_out = 'T0'+obs_in\n",
    "    if len(obs_in) == 3:\n",
    "        obs_out = 'T'+obs_in\n",
    "    return(obs_out)\n",
    "\n",
    "hotspot_traps = []\n",
    "for each in traps_with_highest_WNV:\n",
    "    hotspot_traps.append(put_t_back(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate disdance from lat/lon\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3956 # Radius of earth in kilometers = 6371. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only three species have West Nile\n",
    "# # Export DataFrame to map\n",
    "# df_wnv = df_train[df_train['WnvPresent'] == 1]\n",
    "# print(\"Species with West Nile virus: {}.\".format(set(df_wnv['Species'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression can't handle datetime\n",
    "# X_cols_train['Date'] = X_cols_train['Date'].map(datetime.toordinal)\n",
    "# X_cols_kaggle['Date'] = X_cols_kaggle['Date'].map(datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are only used for creating the map and not part of the notebook flow\n",
    "\n",
    "# # Used to plot traps\n",
    "# df_traps = df_kaggle[['Trap','Latitude','Longitude']]\n",
    "# df_traps.drop_duplicates(inplace=True)\n",
    "# df_traps.shape\n",
    "# df_traps.to_csv(f'../data/traps_kaggle.csv')\n",
    "\n",
    "# # Get the traps and export to map\n",
    "# df_traps = df_train[['Trap','Latitude','Longitude']]\n",
    "# df_traps.drop_duplicates(inplace=True)\n",
    "# df_traps.shape\n",
    "# df_traps.to_csv(f'../data/traps_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are only used for creating the map and not part of the notebook flow\n",
    "\n",
    "# # ['2011-08-29' '2011-09-07' '2013-07-17' '2013-07-25' '2013-08-08'\n",
    "# #  '2013-08-15' '2013-08-16' '2013-08-22' '2013-08-29' '2013-09-05']\n",
    "\n",
    "# df_1 = df_spray[df_spray['Date'] == '2011-08-29']\n",
    "# df_1['DateTime'] = pd.to_datetime(df_1['Date'] + \" \" + df_1['Time'])\n",
    "# df_1.to_csv(f'../data/spray-2011-08-29.csv')\n",
    "\n",
    "# df_3 = df_spray[df_spray['Date'] == '2013-07-17']\n",
    "# df_3['DateTime'] = pd.to_datetime(df_3['Date'] + \" \" + df_3['Time'])\n",
    "# df_3.to_csv(f'../data/spray-2013-07-17.csv')\n",
    "\n",
    "# df_4 = df_spray[df_spray['Date'] == '2013-07-25']\n",
    "# df_4['DateTime'] = pd.to_datetime(df_4['Date'] + \" \" + df_4['Time'])\n",
    "# df_4.to_csv(f'../data/spray-2013-07-25.csv')\n",
    "\n",
    "# df_5 = df_spray[df_spray['Date'] == '2013-08-08']\n",
    "# df_5['DateTime'] = pd.to_datetime(df_5['Date'] + \" \" + df_5['Time'])\n",
    "# df_5.to_csv(f'../data/spray-2013-08-08.csv')\n",
    "\n",
    "# df_6 = df_spray[df_spray['Date'] == '2013-08-15']\n",
    "# df_6['DateTime'] = pd.to_datetime(df_6['Date'] + \" \" + df_6['Time'])\n",
    "# df_6.to_csv(f'../data/spray-2013-08-15.csv')\n",
    "\n",
    "# df_7 = df_spray[df_spray['Date'] == '2013-08-16']\n",
    "# df_7['DateTime'] = pd.to_datetime(df_7['Date'] + \" \" + df_7['Time'])\n",
    "# df_7.to_csv(f'../data/spray-2013-08-16.csv')\n",
    "\n",
    "# df_8 = df_spray[df_spray['Date'] == '2013-08-22']\n",
    "# df_8['DateTime'] = pd.to_datetime(df_8['Date'] + \" \" + df_8['Time'])\n",
    "# df_8.to_csv(f'../data/spray-2013-08-22.csv')\n",
    "\n",
    "# df_8 = df_spray[df_spray['Date'] == '2013-08-29']\n",
    "# df_8['DateTime'] = pd.to_datetime(df_8['Date'] + \" \" + df_8['Time'])\n",
    "# df_8.to_csv(f'../data/spray-2013-08-29.csv')\n",
    "\n",
    "# df_8 = df_spray[df_spray['Date'] == '2013-09-05']\n",
    "# df_8['DateTime'] = pd.to_datetime(df_8['Date'] + \" \" + df_8['Time'])\n",
    "# df_8.to_csv(f'../data/spray-2013-09-05.csv')\n",
    "\n",
    "# df_spray_before = read_examine_df(\"../data/spray 2011-09-07-before-1.csv\")\n",
    "# df_spray_before['DateTime'] = pd.to_datetime(df_spray_before['Date'] + \" \" + df_spray_before['Time'])\n",
    "# df_spray_before.to_csv(f'../data/spray-2011-09-07-before-1-d.csv')\n",
    "\n",
    "# df_spray_before = read_examine_df(\"../data/spray 2011-09-07-before-2.csv\")\n",
    "# df_spray_before['DateTime'] = pd.to_datetime(df_spray_before['Date'] + \" \" + df_spray_before['Time'])\n",
    "# df_spray_before.to_csv(f'../data/spray-2011-09-07-before-2-d.csv')\n",
    "\n",
    "# df_spray_before = read_examine_df(\"../data/spray 2011-09-07-after.csv\")\n",
    "# df_spray_before['DateTime'] = pd.to_datetime(df_spray_before['Date'] + \" \" + df_spray_before['Time'])\n",
    "# df_spray_before.to_csv(f'../data/spray-2011-09-07-after-d.csv')\n",
    "\n",
    "# df_spray_before = read_examine_df(\"../data/spray 2011-09-07-NA.csv\")\n",
    "# df_spray_before['DateTime'] = pd.to_datetime(df_spray_before['Date'] + \" \" + df_spray_before['Time'])\n",
    "# df_spray_before.to_csv(f'../data/spray-2011-09-07-NA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color:#4095b5'>Some weather notes</span>\n",
    "\n",
    "Found this online for heating degree day calcualtion example:\n",
    "Anyway, consider a single day, let's say July 1st, when the outside air temperature was 16C throughout the entire day.  A constant temperature throughout an entire day is rather unlikely, I know, but degree days would be a lot easier to understand if the outside air temperature stayed the same...  So, throughout the entire day on July 1st, the outside air temperature (16C) was consistently 1 degree below the base temperature of the building (17C), and we can work out the heating degree days on that day like so:\n",
    "\n",
    "1 degree * 1 day = 1 heating degree day on July 1st\n",
    "\n",
    "If, on July 2nd, the outside temperature was 2 degrees below the base temperature, we'd have:\n",
    "\n",
    "2 degrees * 1 day = 2 heating degree days on July 2nd\n",
    "\n",
    "Let's look at July 3rd - this was a hotter day, and the outside air temperature was 17C, the same as the base temperature (i.e. 0 degrees below the base temperature).  This gives:\n",
    "\n",
    "0 degrees * 1 day = 0 heating degree days on July 3nd\n",
    "\n",
    "On July 4th it was warmer again: 19C.  Again, the number of degrees below the base temperature was zero, giving:\n",
    "\n",
    "0 degrees * 1 day = 0 heating degree days on July 4th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
